{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "DogvcIzPXnNI",
        "outputId": "3e375c8e-965e-4e03-9ae1-fc42935c28a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-24b755c8-cad1-4d01-a0a8-bc8dcd79c2e1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-24b755c8-cad1-4d01-a0a8-bc8dcd79c2e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving English to Bengali For Machine Translation.zip to English to Bengali For Machine Translation.zip\n",
            "Archive:  English to Bengali For Machine Translation.zip\n",
            "  inflating: english_to_bangla.csv   \n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming only one file is uploaded\n",
        "file_name = list(uploaded.keys())[0]\n",
        "!unzip 'English to Bengali For Machine Translation.zip'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SENTENCES = 2000\n",
        "MAX_VOCAB_SIZE = 50000\n",
        "MAX_SEQUENCE_LENGTH = 200\n",
        "# Define the embedding dimension\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "\n",
        "# Model parameters\n",
        "num_layers = 6  # Using 2 layers as specified\n",
        "d_model = 128\n",
        "num_heads = 8\n",
        "d_ff = 2048\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "rvY1LZ6SagyT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "def read_text_file(filename):\n",
        "    lines = []\n",
        "    try:\n",
        "        with open(filename, newline='\\n', encoding='utf-8') as csvfile:\n",
        "            csv_reader = csv.reader(csvfile)\n",
        "            for row in csv_reader:\n",
        "              lines.append(row)\n",
        "              if len(lines) >= NUM_SENTENCES:\n",
        "                break\n",
        "        #print(len(lines))\n",
        "        #print(lines[0])\n",
        "        return lines\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: The file '{filename}' was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "file_name = 'english_to_bangla.csv'\n",
        "# Read the content of the file\n",
        "\n",
        "lines = read_text_file(file_name)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "decoder_input_texts = []\n",
        "decoder_target_texts = []\n",
        "\n",
        "for line in lines:\n",
        "    input_texts.append(line[0])\n",
        "    target_texts.append('<sos> ' + line[1] + ' <eos>')\n",
        "    decoder_input_texts.append('<sos> ' + line[1])\n",
        "    decoder_target_texts.append(line[1] + ' <eos>')\n"
      ],
      "metadata": {
        "id": "5wCGbuKJX5G0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: use tf.data.Dataset.from_generator cover  input_texts,\n",
        "# decoder_input_texts\n",
        "# decoder_target_texts ]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def data_generator():\n",
        "    for i in range(len(input_texts)):\n",
        "        yield (input_texts[i], decoder_input_texts[i], decoder_target_texts[i])\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    data_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Example of how to iterate over the dataset\n",
        "#for input_text, dec_input_text, dec_target_text in dataset.take(5):\n",
        "#    print(f\"Input: {input_text.numpy().decode('utf-8')}\")\n",
        "#    print(f\"Decoder Input: {dec_input_text.numpy().decode('utf-8')}\")\n",
        "#    print(f\"Decoder Target: {dec_target_text.numpy().decode('utf-8')}\")\n"
      ],
      "metadata": {
        "id": "1g4rsvjFYEkD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: TextVectorization on dataset object\n",
        "\n",
        "#MAX_SEQUENCE_LENGTH = max(max(len(input_vectorization(x).numpy()), len(target_vectorization(y).numpy())) for x, y, z in dataset.take(NUM_SENTENCES))\n",
        "\n",
        "# Input Text Vectorization\n",
        "input_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    output_sequence_length=MAX_SEQUENCE_LENGTH # Set this based on the desired sequence length\n",
        ")\n",
        "\n",
        "# Build the vocabulary for the input texts from the dataset\n",
        "input_dataset_for_vocab = dataset.map(lambda x, y, z: x)\n",
        "input_vectorization.adapt(input_dataset_for_vocab.batch(64)) # Batching is important for adapt\n",
        "\n",
        "# Target Text Vectorization\n",
        "target_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    standardize='lower_and_strip_punctuation', # Can adjust standardization for target if needed\n",
        "    output_sequence_length=MAX_SEQUENCE_LENGTH # Set this based on the desired sequence length\n",
        ")\n",
        "\n",
        "# Build the vocabulary for the target texts from the dataset\n",
        "# We use decoder_input_texts and include '<eos>' to build the vocabulary\n",
        "target_dataset_for_vocab = dataset.map(lambda x, y, z: y).concatenate(tf.data.Dataset.from_tensor_slices(['<eos>']))\n",
        "target_vectorization.adapt(target_dataset_for_vocab.batch(64)) # Batching is important for adapt\n",
        "\n",
        "\n",
        "# Apply vectorization to the dataset\n",
        "def vectorize_texts(input_text, decoder_input_text, decoder_target_text):\n",
        "    input_vectorized = input_vectorization(input_text)\n",
        "    decoder_input_vectorized = target_vectorization(decoder_input_text)\n",
        "    decoder_target_vectorized = target_vectorization(decoder_target_text)\n",
        "    return (input_vectorized, decoder_input_vectorized), decoder_target_vectorized\n",
        "\n",
        "vectorized_dataset = dataset.map(vectorize_texts)\n",
        "\n",
        "# Example of how to iterate over the vectorized dataset\n",
        "#for input_vec, dec_input_vec, dec_target_vec in vectorized_dataset.take(5):\n",
        "#    print(f\"Input Vectorized: {input_vec.numpy()}\")\n",
        "#    print(f\"Decoder Input Vectorized: {dec_input_vec.numpy()}\")\n",
        "#    print(f\"Decoder Target Vectorized: {dec_target_vec.numpy()}\")"
      ],
      "metadata": {
        "id": "EM4bBgW7cfzp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Layer, Dense, Embedding, Dropout, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import math"
      ],
      "metadata": {
        "id": "OckchRjhryjy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: split the vectorized_dataset into training and validaation with 80% for trining\n",
        "\n",
        "dataset_size = NUM_SENTENCES #tf.data.experimental.cardinality(vectorized_dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "train_dataset = vectorized_dataset.take(train_size)\n",
        "validation_dataset = vectorized_dataset.skip(train_size).take(val_size)\n",
        "\n",
        "# Optional: Batch the datasets for training\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True) # Add drop_remainder=True\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True) # Add drop_remainder=True\n",
        "\n",
        "# Optional: Prefetch data for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(f\"Total dataset size: {dataset_size}\")\n",
        "# Calculate the actual number of samples after batching with drop_remainder=True\n",
        "actual_train_size = (train_size // BATCH_SIZE) * BATCH_SIZE\n",
        "actual_val_size = (val_size // BATCH_SIZE) * BATCH_SIZE\n",
        "\n",
        "print(f\"Training dataset size: {actual_train_size}\")\n",
        "print(f\"Validation dataset size: {actual_val_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCCSB1Y8dx4Z",
        "outputId": "43aa9659-1345-474d-e43f-377f843e96bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 2000\n",
            "Training dataset size: 1600\n",
            "Validation dataset size: 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add a embedding layer of 128 for the input length of MAX_SEQUENCE_LENGTH\n",
        "\n",
        "# Get the vocabulary size from the vectorization layer\n",
        "input_vocab_size = input_vectorization.vocabulary_size()\n",
        "\n",
        "\n",
        "# Create the embedding layer\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_vocab_size,\n",
        "    EMBEDDING_DIM,\n",
        "    input_length=MAX_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt1iDo3wf50_",
        "outputId": "e9556d20-3218-48b2-c83b-ec07327039df"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding Layer\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, max_seq_len, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Create positional encoding matrix in __init__\n",
        "        pos_encoding = np.zeros((self.max_seq_len, self.d_model))\n",
        "        for pos in range(self.max_seq_len):\n",
        "            for i in range(0, self.d_model, 2):\n",
        "                pos_encoding[pos, i] = math.sin(pos / (10000 ** ((2 * i) / self.d_model)))\n",
        "                if i + 1 < self.d_model:\n",
        "                    pos_encoding[pos, i + 1] = math.cos(pos / (10000 ** ((2 * i) / self.d_model)))\n",
        "\n",
        "        # Store as a non-trainable TensorFlow constant\n",
        "        self.pos_encoding = tf.constant(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        # Ensure the positional encoding is added correctly by slicing\n",
        "        # Correct slicing for 2D pos_encoding: [sequence_length, embedding_dimension]\n",
        "        return inputs + self.pos_encoding[:seq_len, :]"
      ],
      "metadata": {
        "id": "kxebb7GFgfP0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed Forward Network\n",
        "class FeedForwardNetwork(Layer):\n",
        "    def __init__(self, d_model, d_ff, dropout_rate=0.1):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_ff = d_ff\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.dense1 = Dense(self.d_ff, activation='relu')\n",
        "        self.dense2 = Dense(self.d_model)\n",
        "        self.dropout = Dropout(self.dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dropout(x, training=training)\n",
        "        return self.dense2(x)"
      ],
      "metadata": {
        "id": "sufDPSOirYUJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder Layer\n",
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_ff = d_ff\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Multi-Head Self-Attention\n",
        "        self.mha = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.d_model)\n",
        "        self.dropout1 = Dropout(self.dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Feed Forward Network\n",
        "        self.ffn = FeedForwardNetwork(self.d_model, self.d_ff, self.dropout_rate)\n",
        "        self.dropout2 = Dropout(self.dropout_rate)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        # Self-attention with residual connection and layer norm\n",
        "        attn_output = self.mha(inputs, inputs, attention_mask=mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "        # Feed forward with residual connection and layer norm\n",
        "        ffn_output = self.ffn(out1, training=training)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n"
      ],
      "metadata": {
        "id": "iHjThVqiuQzD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "class Encoder(Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size, max_seq_len, dropout_rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, d_ff, dropout_rate)\n",
        "                          for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        # Embedding and positional encoding\n",
        "        x = self.embedding(inputs)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) ##\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # Pass through encoder layers\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9Wey80fKvgns"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder Layer\n",
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_ff = d_ff\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Masked Multi-Head Self-Attention\n",
        "        self.mha1 = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.d_model)\n",
        "        self.dropout1 = Dropout(self.dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Multi-Head Cross-Attention\n",
        "        self.mha2 = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.d_model)\n",
        "        self.dropout2 = Dropout(self.dropout_rate)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Feed Forward Network\n",
        "        self.ffn = FeedForwardNetwork(self.d_model, self.d_ff, self.dropout_rate)\n",
        "        self.dropout3 = Dropout(self.dropout_rate)\n",
        "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs, encoder_output, training=None, look_ahead_mask=None, padding_mask=None):\n",
        "        # Masked self-attention with residual connection and layer norm\n",
        "        attn1 = self.mha1(inputs, inputs, attention_mask=look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn1)\n",
        "\n",
        "        # Cross-attention with residual connection and layer norm\n",
        "        attn2 = self.mha2(out1, encoder_output, attention_mask=padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "\n",
        "        # Feed forward with residual connection and layer norm\n",
        "        ffn_output = self.ffn(out2, training=training)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(out2 + ffn_output)\n",
        "\n",
        "        return out3"
      ],
      "metadata": {
        "id": "O4ciXcvQvVcG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "class Decoder(Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, target_vocab_size, max_seq_len, dropout_rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, d_ff, dropout_rate)\n",
        "                          for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, inputs, encoder_output, training=None, look_ahead_mask=None, padding_mask=None):\n",
        "        # Embedding and positional encoding\n",
        "        x = self.embedding(inputs)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # Pass through decoder layers\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.dec_layers[i](x, encoder_output, training=training,\n",
        "                                 look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ELDpKXj_zczk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Complete Transformer Model\n",
        "class Transformer(Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size,\n",
        "                 target_vocab_size, max_seq_len, dropout_rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        # Use 2 encoder layers and 2 decoder layers as specified\n",
        "        self.encoder = Encoder(2, d_model, num_heads, d_ff, input_vocab_size,\n",
        "                              max_seq_len, dropout_rate)\n",
        "        self.decoder = Decoder(2, d_model, num_heads, d_ff, target_vocab_size,\n",
        "                              max_seq_len, dropout_rate)\n",
        "\n",
        "        # Final dense layer and softmax\n",
        "        self.final_layer = Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        inp, tar = inputs\n",
        "\n",
        "        # Create masks\n",
        "        enc_padding_mask = self.create_padding_mask(inp)\n",
        "        dec_padding_mask = self.create_padding_mask(inp)\n",
        "        look_ahead_mask = self.create_look_ahead_mask(tf.shape(tar)[1])\n",
        "        dec_target_padding_mask = self.create_padding_mask(tar)\n",
        "        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "        # Encoder output\n",
        "        enc_output = self.encoder(inp, training=training, mask=enc_padding_mask)\n",
        "\n",
        "        # Decoder output\n",
        "        dec_output = self.decoder(tar, enc_output, training=training,\n",
        "                                look_ahead_mask=combined_mask,\n",
        "                                padding_mask=dec_padding_mask)\n",
        "\n",
        "        # Final linear layer with softmax\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    def create_padding_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Creates a mask to hide padding tokens (zeros) in the sequence.\n",
        "\n",
        "        Args:\n",
        "            seq: Input sequence tensor of shape (batch_size, seq_len)\n",
        "\n",
        "        Returns:\n",
        "            Mask tensor of shape (batch_size, 1, 1, seq_len) where:\n",
        "            - 1.0 = mask this position (it's a padding token)\n",
        "            - 0.0 = don't mask this position (it's a real token)\n",
        "        \"\"\"\n",
        "        # Step 1: Find where the sequence has padding tokens (value = 0)\n",
        "        # This creates True where seq == 0, False elsewhere\n",
        "        is_padding = tf.math.equal(seq, 0)\n",
        "\n",
        "        # Step 2: Convert boolean to float (True->1.0, False->0.0)\n",
        "        mask = tf.cast(is_padding, tf.float32)\n",
        "\n",
        "        # Step 3: Add extra dimensions for broadcasting with attention weights\n",
        "        # Shape changes from (batch_size, seq_len) to (batch_size, 1, 1, seq_len)\n",
        "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def create_look_ahead_mask(self, size):\n",
        "        \"\"\"\n",
        "        Creates a triangular mask to prevent the decoder from seeing future tokens.\n",
        "        This ensures that when predicting token at position i, we can only see\n",
        "        tokens at positions 0, 1, 2, ..., i-1.\n",
        "\n",
        "        Args:\n",
        "            size: Length of the sequence\n",
        "\n",
        "        Returns:\n",
        "            Mask tensor of shape (size, size) where:\n",
        "            - 1.0 = mask this position (future token, shouldn't be seen)\n",
        "            - 0.0 = don't mask this position (past/current token, can be seen)\n",
        "\n",
        "        Example for size=4:\n",
        "        [[0, 1, 1, 1],    # Position 0 can only see itself\n",
        "         [0, 0, 1, 1],    # Position 1 can see positions 0,1\n",
        "         [0, 0, 0, 1],    # Position 2 can see positions 0,1,2\n",
        "         [0, 0, 0, 0]]    # Position 3 can see positions 0,1,2,3\n",
        "        \"\"\"\n",
        "        # Step 1: Create a matrix of all ones\n",
        "        ones_matrix = tf.ones((size, size))\n",
        "\n",
        "        # Step 2: Create lower triangular matrix (including diagonal)\n",
        "        # band_part(matrix, -1, 0) keeps lower triangle + diagonal\n",
        "        lower_triangular = tf.linalg.band_part(ones_matrix, -1, 0)\n",
        "\n",
        "        # Step 3: Subtract from 1 to flip the mask\n",
        "        # Lower triangle becomes 0 (don't mask), upper triangle becomes 1 (mask)\n",
        "        look_ahead_mask = 1 - lower_triangular\n",
        "\n",
        "        return look_ahead_mask"
      ],
      "metadata": {
        "id": "oZwwSJOmzjRf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Setup\n",
        "def create_model(input_vocab_size, target_vocab_size, max_seq_len): # Removed default value\n",
        "    # Create model\n",
        "    transformer = Transformer(\n",
        "        num_layers=num_layers,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        d_ff=d_ff,\n",
        "        input_vocab_size=input_vocab_size,\n",
        "        target_vocab_size=target_vocab_size,\n",
        "        max_seq_len=max_seq_len,\n",
        "        dropout_rate=dropout_rate\n",
        "    )\n",
        "\n",
        "    return transformer"
      ],
      "metadata": {
        "id": "X01hHo4k58Ds"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Inference Model\n",
        "class TranslationInference:\n",
        "    def __init__(self, trained_model, input_vectorizer, target_vectorizer, max_length=100):\n",
        "        self.model = trained_model\n",
        "        self.input_vectorizer = input_vectorizer\n",
        "        self.target_vectorizer = target_vectorizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Get vocabularies\n",
        "        self.input_vocab = input_vectorizer.get_vocabulary()\n",
        "        self.target_vocab = target_vectorizer.get_vocabulary()\n",
        "\n",
        "        # Create reverse vocabulary for target language\n",
        "        self.target_index_lookup = {i: token for i, token in enumerate(self.target_vocab)}\n",
        "\n",
        "        # Get special tokens\n",
        "        self.start_token_id = self.target_vectorizer(['<sos>'])[0][0].numpy()\n",
        "        self.end_token_id = self.target_vectorizer(['<eos>'])[0][0].numpy()\n",
        "\n",
        "    def translate(self, sentence):\n",
        "        # Tokenize input sentence\n",
        "        inputs = self.input_vectorizer([sentence])\n",
        "        inputs = tf.expand_dims(inputs[0], 0)\n",
        "\n",
        "        # Initialize decoder input with start token\n",
        "        decoder_input = tf.expand_dims([self.start_token_id], 0)\n",
        "\n",
        "        for i in range(self.max_length):\n",
        "            # Get predictions\n",
        "            predictions = self.model([inputs, decoder_input], training=False)\n",
        "\n",
        "            # Select the last token from the seq_len dimension\n",
        "            predictions = predictions[:, -1:, :]\n",
        "            predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "            # Concatenate the predicted_id to the output\n",
        "            decoder_input = tf.concat([decoder_input, predicted_id], axis=-1)\n",
        "\n",
        "            # Check for end token\n",
        "            if predicted_id[0, 0] == self.end_token_id:\n",
        "                break\n",
        "\n",
        "        # Convert tokens to text\n",
        "        result = decoder_input[0].numpy()\n",
        "        predicted_tokens = [self.target_index_lookup.get(token_id, '<UNK>')\n",
        "                           for token_id in result[1:]]  # Skip start token\n",
        "\n",
        "        # Remove end token if present and join\n",
        "        if '<eos>' in predicted_tokens:\n",
        "            predicted_tokens = predicted_tokens[:predicted_tokens.index('<eos>')]\n",
        "\n",
        "        predicted_sentence = ' '.join(predicted_tokens)\n",
        "        return predicted_sentence\n"
      ],
      "metadata": {
        "id": "3mt8iMfn6qBE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model(model, train_dataset, val_dataset, epochs=10):\n",
        "    # Compile model with standard loss (no need for custom masked loss)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n",
        "    ]\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "fbjsw1iR8_-M"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = len(input_vectorization.get_vocabulary())\n",
        "target_vocab_size = len(target_vectorization.get_vocabulary())\n",
        "\n",
        "print(f\"Input vocabulary size: {input_vocab_size}\")\n",
        "print(f\"Target vocabulary size: {target_vocab_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMzIkSf89Mls",
        "outputId": "037240b6-e00e-4b6c-cb79-ddbf5247860e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input vocabulary size: 1913\n",
            "Target vocabulary size: 3094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(input_vocab_size, target_vocab_size, MAX_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "id": "ZlSsTmE6-O2L"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model, train_dataset, validation_dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yKhTi4u-_I2",
        "outputId": "97a6c762-1813-40fc-a261-1ef5cb33bd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9/Unknown \u001b[1m139s\u001b[0m 12s/step - accuracy: 0.6305 - loss: 6.6793"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-F_xe4jVBgQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model_architecture.png',\n",
        "           show_shapes=True, show_layer_names=True, show_layer_activations=True,\n",
        "           show_dtype=True,  expand_nested=True, show_trainable=False)\n"
      ],
      "metadata": {
        "id": "dUvIgW3PBxHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference = TranslationInference(model, input_vectorization, target_vectorization)\n",
        "\n",
        "english_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I love programming.\",\n",
        "    \"The weather is beautiful today.\",\n",
        "    \"Thank you for your help.\",\n",
        "    \"What is your name?\"\n",
        "]\n",
        "\n",
        "print(\"\\nTranslation Examples:\")\n",
        "print(\"=\" * 50)\n",
        "for sentence in english_sentences:\n",
        "    try:\n",
        "        translation = inference.translate(sentence)\n",
        "        print(f\"English: {sentence}\")\n",
        "        print(f\"Bengali: {translation}\")\n",
        "        print(\"-\" * 30)\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating '{sentence}': {e}\")"
      ],
      "metadata": {
        "id": "IgpbM413CUal"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}