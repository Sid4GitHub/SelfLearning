{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea94827-3c4d-48b9-919e-5630a070d64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\ngpus = tf.config.list_physical_devices('GPU')\\nif gpus:\\n    try:\\n        for gpu in gpus:\\n            tf.config.experimental.set_memory_growth(gpu, True)\\n    except RuntimeError as e:\\n        print(e)\\n        \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682bdcc2-c0e6-485c-ac45-f19bfc220802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 18:45:53.938299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750445153.964169   13217 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750445153.971623   13217 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750445153.995243   13217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750445153.995322   13217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750445153.995324   13217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750445153.995327   13217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-20 18:45:54.003848: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])  # 4GB limit\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5ea199-fa48-4354-b96a-7dd34738ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SENTENCES = 4500 # Use only the first 20,000 records.\n",
    "MAX_NUM_WORDS = 10000 # Use 20,000 words for tokenizing\n",
    "MAX_SENT_LEN = 150\n",
    "\n",
    "EMBEDDING_SIZE = 100\n",
    "\n",
    "LSTM_NEURONS = 300\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2defb96-9423-4428-b363-0ba466a7a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_text_file(filename): \n",
    "    lines = []\n",
    "    try:\n",
    "        with open(filename, newline='\\n', encoding='utf-8') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            for row in csv_reader:\n",
    "              lines.append(row)\n",
    "        #print(len(lines))\n",
    "        #print(lines[0])\n",
    "        return lines\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file '{filename}' was not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "    \n",
    "\n",
    "file_name = '/mnt/d/Work/wsl/ML-DS/english_to_bangla.csv'\n",
    "# Read the content of the file\n",
    "lines = read_text_file(file_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7395b54-d106-4276-9255-953df286e5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a child in a pink dress is climbing up a set of stairs in an entry way .',\n",
       " 'একটি গোলাপী জামা পরা বাচ্চা মেয়ে একটি বাড়ির প্রবেশ পথের সিঁড়ি বেয়ে উঠছে।']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168fc765-3516-4d49-9f40-9785d828a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inputs = 5001\n",
      "Total intermediate outputs = 5001\n",
      "Total outputs = 5001\n",
      "\n",
      "Sample:\n",
      "two dogs on pavement moving toward each other .\n",
      "<sos> রাস্তার পাশে দুইটি কুকুর পরস্পরের দিকে এগিয়ে যাচ্ছ।\n",
      "রাস্তার পাশে দুইটি কুকুর পরস্পরের দিকে এগিয়ে যাচ্ছ। <eos>\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs_i = []\n",
    "outputs = []\n",
    "\n",
    " \n",
    "count = 0\n",
    "for line in lines: \n",
    "    if count > NUM_SENTENCES:\n",
    "        break\n",
    "    count += 1 \n",
    "    ip = line[0].rstrip()\n",
    "    temp_op = line[1].rstrip()\n",
    "    op_i = '<sos> '+temp_op\n",
    "    op = temp_op+' <eos>'\n",
    "    inputs.append(ip)\n",
    "    outputs_i.append(op_i)\n",
    "    outputs.append(op)\n",
    "\n",
    "print('Total inputs =', len(inputs))\n",
    "print('Total intermediate outputs =', len(outputs_i))\n",
    "print('Total outputs =', len(outputs))\n",
    "print('\\nSample:')\n",
    "print(inputs[10])\n",
    "print(outputs_i[10])\n",
    "print(outputs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de015426-186f-41b7-a844-8864f5534d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in input: 3230\n",
      "Length of longest sentence in input: 33\n",
      "Total unique words in output: 5375\n",
      "Length of longest sentence in output: 33\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(inputs)\n",
    "\n",
    "inputs_seq = input_tokenizer.texts_to_sequences(inputs)\n",
    "\n",
    "inputs_word2index = input_tokenizer.word_index\n",
    "print('Total unique words in input:', len(inputs_word2index))\n",
    "\n",
    "inputs_numwords = len(inputs_word2index)+1\n",
    "\n",
    "inputs_maxlen = max(len(s) for s in inputs_seq)\n",
    "print('Length of longest sentence in input:', inputs_maxlen)\n",
    "\n",
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "output_tokenizer.fit_on_texts(outputs_i + outputs)\n",
    "\n",
    "outputs_i_seq = output_tokenizer.texts_to_sequences(outputs_i)\n",
    "outputs_seq = output_tokenizer.texts_to_sequences(outputs)\n",
    "\n",
    "outputs_word2index = output_tokenizer.word_index\n",
    "print('Total unique words in output:', len(outputs_word2index))\n",
    "\n",
    "outputs_numwords = len(outputs_word2index)+1\n",
    "\n",
    "outputs_maxlen = max(len(s) for s in outputs_seq)\n",
    "print('Length of longest sentence in output:', outputs_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999639a8-16db-4331-ac77-47c21e06c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences shape: (5001, 33)\n",
      "decoder_inputs_sequences shape: (5001, 33)\n",
      "decoder_output_sequences shape: (5001, 33)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_input_sequences = pad_sequences(inputs_seq, maxlen=inputs_maxlen)\n",
    "print('encoder_input_sequences shape:', encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(outputs_i_seq, maxlen=outputs_maxlen, padding='post')\n",
    "print('decoder_inputs_sequences shape:', decoder_input_sequences.shape)\n",
    "\n",
    "decoder_output_sequences = pad_sequences(outputs_seq, maxlen=outputs_maxlen, padding='post')\n",
    "print('decoder_output_sequences shape:', decoder_output_sequences.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65dcdad5-e802-4cdf-9370-ac0392cb1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray, zeros\n",
    " \n",
    "embeddings_dict = dict()\n",
    "glove_file = open(f'/mnt/d/Work/wsl/ML-DS/glove.6B.{EMBEDDING_SIZE}d.txt', encoding='utf-8') \n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vector\n",
    "\n",
    "glove_file.close()\n",
    "\n",
    "num_words = min(MAX_NUM_WORDS, len(inputs_word2index)+1)\n",
    "\n",
    "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
    "\n",
    "for word, index in inputs_word2index.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d80e703-3c32-4101-a4aa-1506ac8b34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/envs/tensorflow-2.19_new/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1750445175.707398   13217 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3072 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_outputs_onehot shape: (5001, 33, 5376)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "model_mode = 1\n",
    "\n",
    "if (model_mode == 1) :\n",
    "    encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=inputs_maxlen)\n",
    "    decoder_embedding_layer = Embedding(outputs_numwords, LSTM_NEURONS)\n",
    "    \n",
    "    decoder_outputs_onehot = zeros((len(inputs), outputs_maxlen, outputs_numwords), dtype='float32')\n",
    "    print('decoder_outputs_onehot shape:', decoder_outputs_onehot.shape)\n",
    "    \n",
    "    for i, d in enumerate(decoder_output_sequences):\n",
    "        for t, w in enumerate(d):\n",
    "            decoder_outputs_onehot[i, t, w] = 1\n",
    "    \n",
    "    encoder_inputs = Input(shape=(inputs_maxlen,))\n",
    "    encoder_inputs_emb = encoder_embedding_layer(encoder_inputs)\n",
    "    encoder = LSTM(LSTM_NEURONS, return_state=True)\n",
    "    encoder_outputs, h, c = encoder(encoder_inputs_emb)\n",
    "    encoder_states = [h, c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(outputs_maxlen,))\n",
    "    decoder_inputs_emb = decoder_embedding_layer(decoder_inputs)\n",
    "    decoder = LSTM(LSTM_NEURONS, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder(decoder_inputs_emb, initial_state=encoder_states)\n",
    "    \n",
    "    output_dense_layer = Dense(outputs_numwords, activation='softmax')\n",
    "    outputs = output_dense_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97d5a2c-f728-4ef0-8a33-c7da92720e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">323,100</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,612,800</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">481,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,618,176</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m323,100\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,612,800\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),     │    \u001b[38;5;34m481,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m300\u001b[0m), │    \u001b[38;5;34m721,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m5376\u001b[0m)  │  \u001b[38;5;34m1,618,176\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,476</span> (18.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,756,476\u001b[0m (18.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,476</span> (18.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,756,476\u001b[0m (18.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889cd88-a447-4b00-90ed-92f08fd3a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \n",
    "                                        min_delta=0.001,\n",
    "                                        patience=5,\n",
    "                                        restore_best_weights=True, \n",
    "                                        verbose=1,\n",
    "                                        mode='auto')\n",
    "trn = model.fit([encoder_input_sequences, decoder_input_sequences],\n",
    "               decoder_outputs_onehot, \n",
    "               batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2,\n",
    "                callbacks=[early_stopping_callback]\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791e673-8f8a-4010-b972-56f7c5c9f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = 'NUM_SENTENCES_' + str(NUM_SENTENCES) + \"_EMBEDDING_SIZE_\" + str(EMBEDDING_SIZE) + '_LSTM_NEURONS_' + str(LSTM_NEURONS) + '_model_mode_' + str(model_mode) \n",
    "folder_name = '/mnt/d/Work/wsl/ML-DS/saved_models/EnglishtoBengaliForMachineTranslation/model/' + save_path\n",
    "print(folder_name)\n",
    "# Save to a directory in the TensorFlow SavedModel format (recommended)\n",
    "#model.save(folder_name+\"/model.keras\")\n",
    "\n",
    "# Or save as a single HDF5 file (legacy Keras format)\n",
    "#model.save(folder_name + '/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9a0a1-1662-468e-8162-ba2e4556492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "print(encoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63587b-7dcf-4971-97a2-92d415098e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_h = Input(shape=(LSTM_NEURONS,))\n",
    "decoder_input_c = Input(shape=(LSTM_NEURONS,))\n",
    "decoder_input_states = [decoder_input_h, decoder_input_c]\n",
    "\n",
    "decoder_input_word = Input(shape=(1,))\n",
    "decoder_input_word_emb = decoder_embedding_layer(decoder_input_word)\n",
    "\n",
    "decoder_outputs, h, c = decoder(decoder_input_word_emb, initial_state=decoder_input_states)\n",
    "decoder_states = [h, c]\n",
    "\n",
    "outputs = output_dense_layer(decoder_outputs)\n",
    "\n",
    "\n",
    "decoder_model = Model([decoder_input_word]+decoder_input_states, [outputs]+decoder_states)\n",
    "print(decoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d319fb2-6050-46ec-8a0b-81a688b2a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "index_to_word_input = {v:k for k,v in inputs_word2index.items()}\n",
    "index_to_word_output = {v:k for k,v in outputs_word2index.items()}\n",
    "\n",
    "def translate(input_seq):\n",
    "    states = encoder_model.predict(input_seq)\n",
    "    \n",
    "    sos = outputs_word2index['<sos>']\n",
    "    eos = outputs_word2index['<eos>']\n",
    "    \n",
    "    output_seq = zeros((1, 1))\n",
    "    output_seq[0, 0] = sos\n",
    "    \n",
    "    output_sentence = []\n",
    "    \n",
    "    for _ in range(outputs_maxlen):\n",
    "        output_tokens, h, c = decoder_model.predict([output_seq]+states)\n",
    "        idx = argmax(output_tokens[0, 0, :])\n",
    "        \n",
    "        if idx == eos:\n",
    "            break     \n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = index_to_word_output[idx]\n",
    "            output_sentence.append(word)\n",
    "        \n",
    "        states = [h, c]\n",
    "        output_seq[0, 0] = idx\n",
    "    \n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61354c3-212f-4013-8c31-2ccf45ca5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "i = random.choice(len(inputs))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate(input_seq)\n",
    "\n",
    "print('Input:', inputs[i])\n",
    "print('Response:', translation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a361d7-e22d-43a8-9601-2b3c62b8c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_inputs = ['I am good']\n",
    "my_inputs_seq = input_tokenizer.texts_to_sequences(my_inputs)\n",
    "my_encoder_input_sequences = pad_sequences(my_inputs_seq, maxlen=inputs_maxlen)\n",
    "\n",
    "translation = translate(my_encoder_input_sequences[0:1])\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63710f75-b4df-4751-be6c-f6cc09b36458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
