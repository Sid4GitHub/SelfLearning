{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "-- https://huggingface.co/docs/transformers/en/model_doc/bert\n",
        "-- https://huggingface.co/csebuetnlp/banglabert\n",
        "-- based on above pre-tained model create english to bengali translation\n",
        "-- Floow transformer architecture\n",
        "-- use bert in encoder\n",
        "-- use banglabert in decoder\n",
        "-- use pytorch\n",
        "-- put all hyber paramter in a config map like file path for english_to_bangla.csv, number of sentences, max_sentence length, vocab size, dmodel, learing rate, dff etc\n",
        "-- input file is a csv with two colum named en, bn\n",
        "-- fine rune the model with input file\n",
        "-- add few example to test the translation\n",
        "-- do not put comment\n"
      ],
      "metadata": {
        "id": "YmV-WqZWfiAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming only one file is uploaded\n",
        "file_name = list(uploaded.keys())[0]\n",
        "!unzip 'English to Bengali For Machine Translation Pre-Train.zip'\n"
      ],
      "metadata": {
        "id": "rGe9OS11fkyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "config = {\n",
        "    'data_path': 'english_to_bangla.csv',\n",
        "    'max_sentence_length': 128,\n",
        "    'vocab_size': 30522,\n",
        "    'd_model': 768,\n",
        "    'learning_rate': 2e-5,\n",
        "    'batch_size': 16,\n",
        "    'num_epochs': 1000,\n",
        "    'dff': 2048,\n",
        "    'num_heads': 12,\n",
        "    'num_layers': 6,\n",
        "    'dropout': 0.1,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'early_stop_patience': 8,\n",
        "    'early_stop_min_delta': 0.001,\n",
        "    'max_translation_pairs': 39050\n",
        "}\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, english_texts, bengali_texts, en_tokenizer, bn_tokenizer, max_length):\n",
        "        self.english_texts = english_texts\n",
        "        self.bengali_texts = bengali_texts\n",
        "        self.en_tokenizer = en_tokenizer\n",
        "        self.bn_tokenizer = bn_tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        en_text = str(self.english_texts[idx])\n",
        "        bn_text = str(self.bengali_texts[idx])\n",
        "\n",
        "        en_encoding = self.en_tokenizer(\n",
        "            en_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        bn_encoding = self.bn_tokenizer(\n",
        "            bn_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'en_input_ids': en_encoding['input_ids'].flatten(),\n",
        "            'en_attention_mask': en_encoding['attention_mask'].flatten(),\n",
        "            'bn_input_ids': bn_encoding['input_ids'].flatten(),\n",
        "            'bn_attention_mask': bn_encoding['attention_mask'].flatten()\n",
        "        }\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        # Check if validation loss improved significantly\n",
        "        if val_loss < (self.best_loss - self.min_delta):\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            self.early_stop = False\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            print(f\"EarlyStopping counter: {self.counter}/{self.patience}\")\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, num_layers, dff, max_length, dropout=0.1):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_length)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=dff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
        "        tgt = torch.clamp(tgt, 0, self.vocab_size - 1)\n",
        "\n",
        "        seq_len = tgt.size(1)\n",
        "        tgt = self.embedding(tgt) * np.sqrt(self.d_model)\n",
        "        tgt = self.pos_encoding(tgt.transpose(0, 1)).transpose(0, 1)\n",
        "        tgt = self.dropout(tgt)\n",
        "\n",
        "        if tgt_mask is None:\n",
        "            tgt_mask = self.generate_square_subsequent_mask(seq_len).to(tgt.device)\n",
        "\n",
        "        output = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask)\n",
        "        output = self.fc_out(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
        "        return mask\n",
        "\n",
        "class EnglishToBengaliTranslator(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(EnglishToBengaliTranslator, self).__init__()\n",
        "\n",
        "        self.bert_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        for param in self.bert_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        bn_tokenizer = AutoTokenizer.from_pretrained('csebuetnlp/banglabert')\n",
        "        self.bn_vocab_size = bn_tokenizer.vocab_size\n",
        "\n",
        "        self.decoder = TransformerDecoder(\n",
        "            vocab_size=self.bn_vocab_size,\n",
        "            d_model=config['d_model'],\n",
        "            num_heads=config['num_heads'],\n",
        "            num_layers=config['num_layers'],\n",
        "            dff=config['dff'],\n",
        "            max_length=config['max_sentence_length'],\n",
        "            dropout=config['dropout']\n",
        "        )\n",
        "\n",
        "    def forward(self, en_input_ids, en_attention_mask, bn_input_ids, bn_attention_mask):\n",
        "        encoder_outputs = self.bert_encoder(\n",
        "            input_ids=en_input_ids,\n",
        "            attention_mask=en_attention_mask\n",
        "        )\n",
        "\n",
        "        memory = encoder_outputs.last_hidden_state\n",
        "        memory_mask = ~en_attention_mask.bool()\n",
        "\n",
        "        decoder_input = bn_input_ids[:, :-1]\n",
        "        decoder_input = torch.clamp(decoder_input, 0, self.bn_vocab_size - 1)\n",
        "\n",
        "        decoder_output = self.decoder(\n",
        "            tgt=decoder_input,\n",
        "            memory=memory,\n",
        "            memory_mask=memory_mask\n",
        "        )\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "def create_sample_data():\n",
        "    sample_data = {\n",
        "        'en': [\n",
        "            \"Hello, how are you?\",\n",
        "            \"I love you.\",\n",
        "            \"What is your name?\",\n",
        "            \"Good morning.\",\n",
        "            \"Thank you very much.\",\n",
        "            \"The weather is nice today.\",\n",
        "            \"I am fine.\",\n",
        "            \"Where are you from?\",\n",
        "            \"How old are you?\",\n",
        "            \"Nice to meet you.\"\n",
        "        ],\n",
        "        'bn': [\n",
        "            \"হ্যালো, আপনি কেমন আছেন?\",\n",
        "            \"আমি তোমাকে ভালোবাসি।\",\n",
        "            \"আপনার নাম কি?\",\n",
        "            \"সুপ্রভাত।\",\n",
        "            \"আপনাকে অনেক ধন্যবাদ।\",\n",
        "            \"আজ আবহাওয়া সুন্দর।\",\n",
        "            \"আমি ভালো আছি।\",\n",
        "            \"আপনি কোথা থেকে এসেছেন?\",\n",
        "            \"আপনার বয়স কত?\",\n",
        "            \"আপনার সাথে দেখা করে ভালো লাগলো।\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    df.to_csv('english_to_bangla.csv', index=False)\n",
        "    return df\n",
        "\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config['data_path']):\n",
        "        print(f\"Creating sample data at {config['data_path']}\")\n",
        "        df = create_sample_data()\n",
        "    else:\n",
        "        df = pd.read_csv(config['data_path'])\n",
        "\n",
        "    if config['max_translation_pairs'] > 0:\n",
        "        df = df.head(config['max_translation_pairs'])\n",
        "        print(f\"Loaded {len(df)} translation pairs (limited by max_translation_pairs)\")\n",
        "    else:\n",
        "        print(f\"Loaded {len(df)} translation pairs\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def validate_model(model, val_loader, criterion, config):\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    valid_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            try:\n",
        "                en_input_ids = batch['en_input_ids'].to(config['device'])\n",
        "                en_attention_mask = batch['en_attention_mask'].to(config['device'])\n",
        "                bn_input_ids = batch['bn_input_ids'].to(config['device'])\n",
        "                bn_attention_mask = batch['bn_attention_mask'].to(config['device'])\n",
        "\n",
        "                outputs = model(en_input_ids, en_attention_mask, bn_input_ids, bn_attention_mask)\n",
        "\n",
        "                targets = bn_input_ids[:, 1:].contiguous()\n",
        "                targets = torch.clamp(targets, 0, outputs.size(-1) - 1)\n",
        "                outputs = outputs.contiguous()\n",
        "\n",
        "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
        "                total_val_loss += loss.item()\n",
        "                valid_batches += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error in validation batch: {e}\")\n",
        "                continue\n",
        "\n",
        "    if valid_batches == 0:\n",
        "        print(\"Warning: No valid validation batches processed\")\n",
        "        return float('inf')\n",
        "\n",
        "    avg_val_loss = total_val_loss / valid_batches\n",
        "    return avg_val_loss\n",
        "\n",
        "def train_model(model, train_loader, val_loader, config):\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "    early_stopping = EarlyStopping(\n",
        "        patience=config['early_stop_patience'],\n",
        "        min_delta=config['early_stop_min_delta']\n",
        "    )\n",
        "\n",
        "    best_model_state = None\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    print(f\"Starting training with early stopping (patience={config['early_stop_patience']}, min_delta={config['early_stop_min_delta']})\")\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        valid_batches = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]}')\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            try:\n",
        "                en_input_ids = batch['en_input_ids'].to(config['device'])\n",
        "                en_attention_mask = batch['en_attention_mask'].to(config['device'])\n",
        "                bn_input_ids = batch['bn_input_ids'].to(config['device'])\n",
        "                bn_attention_mask = batch['bn_attention_mask'].to(config['device'])\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(en_input_ids, en_attention_mask, bn_input_ids, bn_attention_mask)\n",
        "\n",
        "                targets = bn_input_ids[:, 1:].contiguous()\n",
        "                targets = torch.clamp(targets, 0, outputs.size(-1) - 1)\n",
        "                outputs = outputs.contiguous()\n",
        "\n",
        "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                valid_batches += 1\n",
        "                progress_bar.set_postfix({'loss': loss.item()})\n",
        "            except Exception as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if valid_batches == 0:\n",
        "            print(\"Warning: No valid training batches processed\")\n",
        "            continue\n",
        "\n",
        "        avg_train_loss = total_loss / valid_batches\n",
        "        avg_val_loss = validate_model(model, val_loader, criterion, config)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Best Val Losss: {best_val_loss:.4f}')\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        if early_stopping(avg_val_loss):\n",
        "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
        "            print(f'Training stopped early. Best validation loss: {early_stopping.best_loss:.4f}')\n",
        "            break\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f'Loaded best model with validation loss: {best_val_loss:.4f}')\n",
        "    else:\n",
        "        print(\"Warning: No best model state saved\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def translate_text(model, text, en_tokenizer, bn_tokenizer, config, max_length=50):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            en_encoding = en_tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=config['max_sentence_length'],\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            en_input_ids = en_encoding['input_ids'].to(config['device'])\n",
        "            en_attention_mask = en_encoding['attention_mask'].to(config['device'])\n",
        "\n",
        "            encoder_outputs = model.bert_encoder(\n",
        "                input_ids=en_input_ids,\n",
        "                attention_mask=en_attention_mask\n",
        "            )\n",
        "\n",
        "            memory = encoder_outputs.last_hidden_state\n",
        "            memory_mask = ~en_attention_mask.bool()\n",
        "\n",
        "            decoder_input = torch.tensor([[bn_tokenizer.cls_token_id if bn_tokenizer.cls_token_id is not None else 0]],\n",
        "                                       device=config['device'])\n",
        "\n",
        "            for _ in range(max_length):\n",
        "                decoder_input_clamped = torch.clamp(decoder_input, 0, model.bn_vocab_size - 1)\n",
        "\n",
        "                decoder_output = model.decoder(\n",
        "                    tgt=decoder_input_clamped,\n",
        "                    memory=memory,\n",
        "                    memory_mask=memory_mask\n",
        "                )\n",
        "\n",
        "                next_token_logits = decoder_output[:, -1, :]\n",
        "                next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "\n",
        "                decoder_input = torch.cat([decoder_input, next_token.unsqueeze(1)], dim=1)\n",
        "\n",
        "                if next_token.item() == bn_tokenizer.sep_token_id:\n",
        "                    break\n",
        "\n",
        "            translated_tokens = decoder_input.squeeze().tolist()\n",
        "            translated_text = bn_tokenizer.decode(translated_tokens, skip_special_tokens=True)\n",
        "\n",
        "            return translated_text\n",
        "        except Exception as e:\n",
        "            print(f\"Error translating text: {e}\")\n",
        "            return f\"Translation failed: {text}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "IZq9VFnPLoG6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Loading data...\")\n",
        "df = load_data(config)\n",
        "\n",
        "print(\"Initializing tokenizers...\")\n",
        "en_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bn_tokenizer = AutoTokenizer.from_pretrained('csebuetnlp/banglabert')\n",
        "\n",
        "print(\"Preparing datasets...\")\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = TranslationDataset(\n",
        "    train_df['en'].tolist(),\n",
        "    train_df['bn'].tolist(),\n",
        "    en_tokenizer,\n",
        "    bn_tokenizer,\n",
        "    config['max_sentence_length']\n",
        ")\n",
        "\n",
        "val_dataset = TranslationDataset(\n",
        "    val_df['en'].tolist(),\n",
        "    val_df['bn'].tolist(),\n",
        "    en_tokenizer,\n",
        "    bn_tokenizer,\n",
        "    config['max_sentence_length']\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "print(\"Initializing model...\")\n",
        "model = EnglishToBengaliTranslator(config).to(config['device'])\n",
        "\n",
        "print(\"Training model...\")\n",
        "model = train_model(model, train_loader, val_loader, config)\n",
        "\n",
        "print(\"Saving model...\")\n",
        "torch.save(model.state_dict(), 'en_bn_translator.pth')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHMyZhx4LpQ5",
        "outputId": "c5d376e3-9d89-4f4d-c37f-2a9fba17dc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Loaded 39050 translation pairs (limited by max_translation_pairs)\n",
            "Initializing tokenizers...\n",
            "Preparing datasets...\n",
            "Initializing model...\n",
            "Training model...\n",
            "Starting training with early stopping (patience=8, min_delta=0.001)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1000:   5%|▌         | 104/1953 [00:42<12:20,  2.50it/s, loss=7.27]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nTesting translations...\")\n",
        "test_sentences = [\n",
        "    \"a child in a pink dress is climbing up a set of stairs in an entry way .\",\n",
        "    \"a girl going into a wooden building .\",\n",
        "    \"a dog is running in the snow\",\n",
        "    \"a dog running\",\n",
        "    \"Hello, how are you?\",\n",
        "    \"a man in an orange hat starring at something .\",\n",
        "    \"I love you.\",\n",
        "    \"a little girl climbing into a wooden playhouse .\",\n",
        "    \"What is your name?\",\n",
        "    \"two dogs of different breeds looking at each other on the road .\",\n",
        "    \"Good morning.\",\n",
        "    \"Thank you very much.\",\n",
        "    \"Hello, how are you?\",\n",
        "    \"I love you.\",\n",
        "    \"What is your name?\",\n",
        "    \"Good morning.\",\n",
        "    \"Thank you very much.\",\n",
        "    \"The weather is nice today.\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    try:\n",
        "        translation = translate_text(model, sentence, en_tokenizer, bn_tokenizer, config)\n",
        "        print(f\"English: {sentence}\")\n",
        "        print(f\"Bengali: {translation}\")\n",
        "        print(\"-\" * 50)\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating '{sentence}': {e}\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "fWzUK4dlRmG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}